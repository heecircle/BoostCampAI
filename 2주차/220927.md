# TIL 220927

부덕아 싸울래? ㅎ 

과제가 너무 많어,, 
죽겄어요,,

일단 배웠던것 공유 + 과제한것을 공유 해보겄다! 

# pytorch 프로젝트 구조

~~~
.
├── callbacks // here you can create your custom callbacks
├── checkpoint // were we store the trained models
├── data // here we define our dataset
│ └── transformation // custom transformation, e.g. resize and data augmentation
├── dataset // the data
│ ├── train
│ └── val
├── logger.py // were we define our logger
├── losses // custom losses
├── main.py
├── models // here we create our models
│ ├── MyCNN.py
│ ├── resnet.py
│ └── utils.py
├── playground.ipynb // a notebook that can be used to fast experiment with things
├── Project.py // a class that represents the project structure
├── README.md
├── requirements.txt
├── test // you should always perform some basic testing
│ └── test_myDataset.py
└── utils.py // utilities functions
~~~

그냥 구조 설명하는 내용이라 3강은 넘어가겠다 !


# torch.nn.Module


- 딥러닝을 구성하는 Layer의 base class
- Input, Output, Forward, Backward 정 의
- 학습의 대상이 되는 parameter(tensor) 정의

## torch.nn.Parmeter

- tensor 객체의 상속객체로, 직접 지정할 일은 잘 없음 

~~~python
class MyLiner(nn.Module):
    def init (self, in_features, out_features, bias=True):
        super().__init__()
        self.in_features=in_features
        self.out_features=out_features
        self.weights = nn.Parameter(torch.randn(in_features, out_features)) 
        self.bias = nn.Parameter(torch.randn(out_features))

    def forward(self, x: Tensor):
        return x @ self.weights + self.bias
~~~